{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52824b89-532a-4e54-87e9-1410813cd39e",
   "metadata": {},
   "source": [
    "# LangChain: Agents\n",
    "\n",
    "## Outline:\n",
    "\n",
    "* Using built in LangChain tools: DuckDuckGo search and Wikipedia\n",
    "* Defining your own tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7ed03ed-1322-49e3-b2a2-33e94fb592ef",
   "metadata": {
    "height": 131,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fd0194-9f3d-4468-9390-f23df83e83c4",
   "metadata": {},
   "source": [
    "Note: LLM's do not always produce the same results. When executing the code in your notebook, you may get slightly different answers that those in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7269176-8094-40ce-bedc-4c6421b16e98",
   "metadata": {
    "height": 233
   },
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3b9ad2",
   "metadata": {},
   "source": [
    "## Built-in LangChain tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "974acf8e-8f88-42de-88f8-40a82cb58e8b",
   "metadata": {
    "height": 29,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install -U wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f3b6f-dfe1-4e44-8ee5-6845a5a6c996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b93d0e8",
   "metadata": {
    "height": 114,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_experimental'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_experimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magent_toolkits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_python_agent\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tools, initialize_agent\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgentType\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_experimental'"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.agents.agent_toolkits.base import create_python_agent\n",
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools.python.tool import PythonREPLTool\n",
    "from langchain.python import PythonREPL\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40f93d4a",
   "metadata": {
    "height": 199
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0 , model = llm_model)\n",
    "# define tools from load_tools\n",
    "tools = load_tools(['llm-math','wikipedia'],llm=llm)\n",
    "agent = initialize_agent(\n",
    "        tools,\n",
    "        llm,\n",
    "        agent = AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        handle_parsing_errors=True,\n",
    "        verbose = True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b71f4cc5",
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I should use Wikipedia to find information about Donald Trump and his election results.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"Donald Trump\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Donald Trump\n",
      "Summary: Donald John Trump (born June 14, 1946) is an American politician, media personality, and businessman who served as the 45th president of the United States from 2017 to 2021. He won the 2024 election as the nominee of the Republican Party and is now the president-elect of the United States.  He is scheduled to begin his second term on January 20, 2025.   \n",
      "Trump graduated with a bachelor's degree in economics from the University of Pennsylvania in 1968. After becoming president of the family real estate business in 1971, he renamed it the Trump Organization. After a series of bankruptcies in the 1990s, he launched side ventures, mostly licensing the Trump name. From 2004 to 2015, he produced and hosted the reality television series The Apprentice. In 2015, Trump launched a presidential campaign which led to the Trumpism movement.\n",
      "Trump won the 2016 presidential election, becoming the first U.S. president without prior military or government service. His election and policies sparked numerous protests.  In his first term, he ordered a travel ban limiting refugees from Muslim-majority countries, funded the Trump wall, and implemented a family separation policy. He rolled back more than 100 environmental policies and regulations and signed the Tax Cuts and Jobs Act of 2017. He appointed three justices to the Supreme Court, initiated a trade war with China, and withdrew the U.S. from several international agreements. He has met with North Korean president Kim Jong Un but made no progress on denuclearization. His reaction to the COVID-19 pandemic has been heavily criticized for being slow and generally imprudent. He was impeached twice: once in 2019 for abuse of power and obstruction of Congress, and again in 2021 for incitement of insurrection. The Senate acquitted him in both cases. \n",
      "Many of Trump's comments and actions have been characterized as racially charged, racist, and misogynistic. He promoted conspiracy theories and made many false and misleading statements during his campaigns and presidency, to a degree unprecedented in American politics. After his first term, scholars and historians ranked him as one of the worst presidents in American history. Trump lost the 2020 presidential election but refused to concede, falsely claiming widespread electoral fraud and attempting to overturn the results, including facilitating the January 6 mob attack at the U.S. Capitol. In 2024, he was found guilty of falsifying business records, making him the first U.S. president to be convicted of a felony. He faced more felony indictments related to his mishandling of classified documents and interference in the 2020 election. \n",
      "\n",
      "\n",
      "\n",
      "Page: Donald Trump Jr.\n",
      "Summary: Donald John Trump Jr. (born December 31, 1977), often nicknamed Don Jr., is an American businessman. He is the eldest child of U.S. president-elect Donald Trump and his first wife Ivana Trump.\n",
      "Trump serves as a trustee and executive vice president of the Trump Organization, running the company alongside his younger brother Eric. During their father's first presidency, the brothers continued to do deals and investments in foreign countries, as well as collect payments in their U.S. properties from foreign governments, despite a pledge that they would not do so. He served as a boardroom judge on the reality TV show featuring his father, The Apprentice. He authored Triggered in 2019 and Liberal Privilege in 2020.\n",
      "Trump was active in his father's 2016 presidential campaign and played a role the campaign's success. Trump campaigned for several Republicans during the 2018 midterm elections. He has promoted several conspiracy theories.\n",
      "Trump was also active in his father's 2020 presidential campaign, often being on the campaign trail and being featured in the news for making unfounded claims. During the election he called for \"total war\" as the results were counted and promoted the stolen election conspiracy theory. Following his father's defeat, he engaged in atte\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should check if Donald Trump won the elections in 2024 as mentioned in the Wikipedia summary.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"United States presidential election, 2024\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: 2024 United States presidential election\n",
      "Summary: The 2024 United States presidential election was the 60th quadrennial presidential election, held on Tuesday, November 5, 2024. The Republican Party's ticket—Donald Trump, who was the 45th president of the United States from 2017 to 2021, and JD Vance, the junior U.S. senator from Ohio—defeated the Democratic Party's ticket—Kamala Harris, the incumbent U.S. vice president, and Tim Walz, the governor of Minnesota. Trump and Vance are scheduled to be inaugurated as the 47th president and the 50th vice president on January 20, 2025, after their formal election by the Electoral College.\n",
      "The incumbent president, Joe Biden of the Democratic Party, initially ran for re-election with Harris as the party's presumptive nominee, facing little opposition; however, what was broadly considered a poor debate performance in June 2024 intensified concerns about his age and health, and led to calls within his party for him to leave the race. After initially declining to do so, Biden withdrew on July 21, becoming the first eligible incumbent president to withdraw since Lyndon B. Johnson in 1968. Biden endorsed Vice President Kamala Harris, who was voted the party's nominee by the delegates on August 5, 2024. Harris selected Walz as her running mate.\n",
      "Trump, who had lost in 2020 to Biden, ran for re-election again. He was nominated during the 2024 Republican National Convention along with his running mate, Vance, after winning the Republican primaries. The Trump campaign was noted for making many false and misleading statements, including the false claim that the 2020 election was stolen from Trump, engaging in anti-immigrant fearmongering, and promoting conspiracy theories. His speeches were widely described as marked by authoritarian and dehumanizing rhetoric toward his political opponents. His campaign and populist political movement were characterized by several historians and former Trump administration officials as featuring parallels to fascism.\n",
      "In May 2024, Trump became the first U.S. president to be convicted of a crime after he was found guilty on multiple felony counts of falsifying business records related to hush money payments made to the pornographic actress Stormy Daniels. He was previously found liable for sex abuse against E. Jean Carroll and for business fraud in New York. He remains under multiple indictments for his attempts to overturn the 2020 election, his role in the January 6 attack on the Capitol, and his election racketeering prosecution in Georgia. Trump survived two assassination attempts in the four months before the election: the first at a rally in Butler, Pennsylvania, and the second at Trump International Golf Club in West Palm Beach, Florida.\n",
      "According to polls, the most important issues for voters were the economy, healthcare, democracy, foreign policy (notably U.S. support for Israel and for Ukraine), violent crime, immigration, gun policy, abortion, racial and ethnic inequality, and climate change. Education and LGBTQ rights were also prominent issues in the campaign. Polled voters consistently cited the economy as being the single most important issue in the election. According to Pew Research, immigration was the second-most important issue to Trump supporters but the least-important issue to Harris supporters.\n",
      "Trump achieved a decisive victory, sweeping every swing state in addition to holding on to all of the states that he won in 2020. Trump flipped six states that had voted Democratic in 2020: Arizona, Georgia, Michigan, Nevada, Pennsylvania, and Wisconsin. Trump won the national popular vote, making him the first Republican to do so since George W. Bush in 2004. He significantly improved his vote share among almost all demographics nationwide, particularly among Hispanic voters, in a working class coalition described as the most racially diverse for a Republican presidential candidate in decades. Having previously won in 2016, Trump became the sec\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: Donald Trump won the 2024 United States presidential election as the Republican Party's nominee and is set to become the 47th president of the United States.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': ' tell me about trump, did he win the elections? ',\n",
       " 'output': \"Donald Trump won the 2024 United States presidential election as the Republican Party's nominee and is set to become the 47th president of the United States.\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\" tell me about trump, did he win the elections? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ee3df6-ded9-4c96-ba47-a6cf636c1b9b",
   "metadata": {},
   "source": [
    "## Wikipedia example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "441df699-0a52-4812-a0a7-4605204f0aa8",
   "metadata": {
    "height": 46,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Who is the author of the \"Attention is All You Need\" paper?\n",
      "Thought: I should use Wikipedia to find the author of the paper.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"Attention is All You Need\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mPage: Attention Is All You Need\n",
      "Summary: \"Attention Is All You Need\" is a 2017 landmark research paper in machine learning authored by eight scientists working at Google. The paper introduced a new deep learning architecture known as the transformer, based on the attention mechanism proposed in 2014 by Bahdanau et al. It is considered a foundational paper in modern artificial intelligence, as the transformer approach has become the main architecture of large language models like those based on GPT. At the time, the focus of the research was on improving Seq2seq techniques for machine translation, but the authors go further in the paper, foreseeing the technique's potential for other tasks like question answering and what is now known as multimodal Generative AI.\n",
      "The paper's title is a reference to the song \"All You Need Is Love\" by the Beatles. The name \"Transformer\" was picked because Uszkoreit liked the sound of that word.\n",
      "An early design document was titled \"Transformers: Iterative Self-Attention and Processing for Various Tasks\", and included an illustration of six characters from the Transformers animated show. The team was named Team Transformer.\n",
      "Some early examples that the team tried their Transformer architecture on included English-to-German translation, generating Wikipedia articles on \"The Transformer\", and parsing. These convinced the team that the Transformer is a general purpose language model, and not just good for translation.\n",
      "As of 2024, the paper has been cited more than 100,000 times.\n",
      "For their 100M-parameter Transformer model, they suggested learning rate should be linearly scaled up from 0 to maximal value for the first part of the training (i.e. 2% of the total number of training steps), and to use dropout, to stabilize training.\n",
      "\n",
      "Page: All You Need Is Kill\n",
      "Summary: All You Need Is Kill is a Japanese science fiction light novel by Hiroshi Sakurazaka with illustrations by Yoshitoshi Abe. The book was published in Japanese by Shueisha under their Super Dash Bunko imprint in December 2004, and was later released in English by Viz Media under their Haikasoru imprint. All You Need Is Kill follows a soldier named Keiji Kiriya, who, after dying in a battle with extraterrestrials, is caught in a time loop that makes him live the same day repeatedly, allowing Kiriya to improve his fighting skills.\n",
      "A manga adaptation, written by Ryōsuke Takeuchi and illustrated by Takeshi Obata, was serialized in Shueisha's Weekly Young Jump magazine between January and May 2014 and was also published by Viz Media in its Weekly Shonen Jump magazine. In November 2014, the Viz translation was released in a collected edition that included the entire series. A separate graphic novel adaptation, written by Nick Mamatas and illustrated by Lee Ferguson, was released in North America in May 2014. A film adaptation from director Doug Liman starring Tom Cruise and Emily Blunt, titled Edge of Tomorrow, was released in May 2014. The English-language film tie-in edition of the novel also uses this title.\n",
      "The novel was Sakurazaka's breakthrough science fiction novel, earning wide praise from fellow novelists including Yasutaka Tsutsui and Chōhei Kanbayashi and was entered in contention for the Best Japanese Long Work in the 36th Seiun Awards in 2005.\n",
      "\n",
      "Page: All You Need Is Love\n",
      "Summary: \"All You Need Is Love\" is a song by the English rock band the Beatles that was released as a non-album single in July 1967, with \"Baby, You're a Rich Man\" as its B-side. It was written by John Lennon and credited to the Lennon–McCartney partnership. The song was Britain's contribution to Our World, the first live global television link, for which the band were filmed performing it at EMI Studios in London on 25 June. The programme was broadcast via satellite and seen by an audience of over 400 million in 25 countries. Lennon's lyrics were deliberately simplistic, to allow for broad appeal to the show's international audience, and captured the utopian ideals asso\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found the information about the author of the \"Attention is All You Need\" paper. \n",
      "Final Answer: The paper \"Attention is All You Need\" was authored by eight scientists working at Google.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"i want to tell me who is the author of attention is all you need paper\"\n",
    "result = agent(question) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90299a00-eb79-4755-bb4b-bf61d88c7fed",
   "metadata": {},
   "source": [
    "## Python Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7617576-d855-4ede-9c1a-be742f1504cf",
   "metadata": {
    "height": 97,
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d05e7dc6-f07e-43df-a2f6-9a0816291861",
   "metadata": {
    "height": 148,
    "tags": []
   },
   "outputs": [],
   "source": [
    "customer_list = [[\"Harrison\", \"Chase\"], \n",
    "                 [\"Lang\", \"Chain\"],\n",
    "                 [\"Dolly\", \"Too\"],\n",
    "                 [\"Elle\", \"Elem\"], \n",
    "                 [\"Geoff\",\"Fusion\"], \n",
    "                 [\"Trance\",\"Former\"],\n",
    "                 [\"Jen\",\"Ayai\"]\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f887f8f9-216e-489a-945a-f38fbccbe5c4",
   "metadata": {
    "height": 63,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWe can use the sorted() function in Python to sort the list of customers based on last name first and then first name.\n",
      "Action: Python REPL\n",
      "Action Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\n",
      "sorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\n",
      "print(sorted_customers)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe customers have been successfully sorted by last name and then first name.\n",
      "Final Answer: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74466cec-2d98-438b-805f-33e31fdc3035",
   "metadata": {},
   "source": [
    "#### View detailed outputs of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12548579-810b-416e-afb5-178296685c2c",
   "metadata": {
    "height": 114,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \\\"I don't know\\\" as the answer.\\n\\n\\nPython REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Python REPL]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] [17.925ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"We can use the sorted() function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"We can use the sorted() function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 326,\n",
      "      \"completion_tokens\": 112,\n",
      "      \"total_tokens\": 438\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [18.258ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"We can use the sorted() function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:Python REPL] Entering Tool run with input:\n",
      "\u001b[0m\"customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\n",
      "sorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\n",
      "print(sorted_customers)\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:tool:Python REPL] [0.22699999999999998ms] Exiting Tool run with output:\n",
      "\u001b[0m\"[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\",\n",
      "  \"agent_scratchpad\": \"We can use the sorted() function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\\nObservation: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\\n\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"\\nObservation:\",\n",
      "    \"\\n\\tObservation:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are an agent designed to write and execute python code to answer questions.\\nYou have access to a python REPL, which you can use to execute python code.\\nIf you get an error, debug your code and try again.\\nOnly use the output of your code to answer the question. \\nYou might know the answer without running any code, but you should still run the code to get the answer.\\nIf it does not seem like you can write code to answer the question, just return \\\"I don't know\\\" as the answer.\\n\\n\\nPython REPL: A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [Python REPL]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: Sort these customers by last name and then first name and print the output: [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nThought:We can use the sorted() function in Python to sort the list of customers based on last name first and then first name.\\nAction: Python REPL\\nAction Input: customers = [['Harrison', 'Chase'], ['Lang', 'Chain'], ['Dolly', 'Too'], ['Elle', 'Elem'], ['Geoff', 'Fusion'], ['Trance', 'Former'], ['Jen', 'Ayai']]\\nsorted_customers = sorted(customers, key=lambda x: (x[1], x[0]))\\nprint(sorted_customers)\\nObservation: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\\n\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:ChatOpenAI] [23.863ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The customers have been successfully sorted by last name and then first name.\\nFinal Answer: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"The customers have been successfully sorted by last name and then first name.\\nFinal Answer: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 495,\n",
      "      \"completion_tokens\": 68,\n",
      "      \"total_tokens\": 563\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\"\n",
      "  }\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 5:chain:LLMChain] [25.728ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"The customers have been successfully sorted by last name and then first name.\\nFinal Answer: [['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [44.841ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"[['Jen', 'Ayai'], ['Lang', 'Chain'], ['Harrison', 'Chase'], ['Elle', 'Elem'], ['Trance', 'Former'], ['Geoff', 'Fusion'], ['Dolly', 'Too']]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "langchain.debug=True\n",
    "agent.run(f\"\"\"Sort these customers by \\\n",
    "last name and then first name \\\n",
    "and print the output: {customer_list}\"\"\") \n",
    "langchain.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a4685",
   "metadata": {},
   "source": [
    "## Define your own tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b32cfe",
   "metadata": {
    "height": 29,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73f8b595",
   "metadata": {
    "height": 46,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.agents import tool\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61c64268",
   "metadata": {
    "height": 165,
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d2fd9ee",
   "metadata": {
    "height": 114,
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f30e7c-77f1-43fc-a966-140f05160378",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "\n",
    "The agent will sometimes come to the wrong conclusion (agents are a work in progress!). \n",
    "\n",
    "If it does, please try running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fcd13cb",
   "metadata": {
    "height": 80,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I can use the `time` tool to find out today's date.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m2024-11-19\u001b[0m\n",
      "Thought:\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will correct the previous action to get today's date properly.\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"time\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\n",
      "\n",
      "Final Answer: 2024-11-19\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    result = agent(\"whats the date today?\") \n",
    "except: \n",
    "    print(\"exception on external access\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0d694e-d6ca-49db-8ea7-a48339af1542",
   "metadata": {},
   "source": [
    "Reminder: Download your notebook to you local computer to save your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4a953-47b3-4cfa-8388-abe4d96070ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9765828-848c-4784-aa25-4be469e70121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd285719-0651-44e9-b2e5-1378a7f2c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc6286-dbde-4906-a45d-355a990e81d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install --upgrade langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0430313-75b4-4620-ad41-4c02b6b91552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Any', 'REMOVED', 'TYPE_CHECKING', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__getattr__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_module_lookup', 'importlib']\n"
     ]
    }
   ],
   "source": [
    "import langchain_community.utilities as utilities\n",
    "print(dir(utilities))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "958fd1e4-b151-49fc-893d-3c5f3b74d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llm_bash.bash import BashProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f36debe-d25d-4b75-b719-2a5ec5193fd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community.utilities.bash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BashProcess\n\u001b[1;32m      3\u001b[0m bash \u001b[38;5;241m=\u001b[39m BashProcess(\n\u001b[1;32m      4\u001b[0m     strip_newlines \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      5\u001b[0m     return_err_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     persistent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m bash\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mecho \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhello world\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community.utilities.bash'"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities.bash import BashProcess\n",
    "\n",
    "bash = BashProcess(\n",
    "    strip_newlines = False,\n",
    "    return_err_output = False,\n",
    "    persistent = False\n",
    ")\n",
    "bash.run(\"echo 'hello world'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178403f1",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import _get_tool_calls_from_response as original_get_tool_calls\n",
    "from uuid import uuid4\n",
    "\n",
    "# Override _get_tool_calls_from_response\n",
    "def _get_tool_calls_from_response(response):\n",
    "    tool_calls = []\n",
    "    if \"message\" in response:\n",
    "        if \"tool_calls\" in response[\"message\"] and response[\"message\"][\"tool_calls\"] is not None:\n",
    "            for tc in response[\"message\"][\"tool_calls\"]:\n",
    "                tool_calls.append(\n",
    "                    tool_call(\n",
    "                        id=str(uuid4()),\n",
    "                        tool_name=tc.get(\"tool_name\"),\n",
    "                        args=tc.get(\"args\"),\n",
    "                    )\n",
    "                )\n",
    "    return tool_calls\n",
    "\n",
    "# Monkey patch\n",
    "import langchain_ollama.chat_models\n",
    "langchain_ollama.chat_models._get_tool_calls_from_response = _get_tool_calls_from_response\n",
    "\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_experimental.agents.agent_toolkits import create_python_agent\n",
    "from langchain_experimental.tools.python.tool import PythonREPLTool\n",
    "from langchain.agents import load_tools\n",
    "from langchain_experimental.llm_bash.bash import BashProcess\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "\n",
    "bash = BashProcess()\n",
    "\n",
    "agent_executor = create_python_agent(\n",
    "    llm = ChatOllama(model=\"llama3.1:latest\", verbose=True),\n",
    "    tool=PythonREPLTool(),\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "agent_executor.invoke(\"\"\"You have access to the terminal through the bash variable. open the terminal and perform ls command on terminal\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da13800c",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d07a599",
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Bonjour Saran !\\n\\nThe translation of the sentence \"translate this sentence to french\" is:\\n\\n\"Traduire cette phrase en français\"\\n\\nOr, if you\\'d like me to translate a specific sentence that you\\'ve written (not just the instruction), please go ahead and share it with me!', additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-11-27T03:23:46.243415Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2058956542, 'load_duration': 34024959, 'prompt_eval_count': 21, 'prompt_eval_duration': 284000000, 'eval_count': 58, 'eval_duration': 1739000000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-27168c75-ca8a-46fa-a1d5-ee1c89e37575-0', usage_metadata={'input_tokens': 21, 'output_tokens': 58, 'total_tokens': 79})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ai_msg = llm.invoke(\"Hey i'm saran - translate this sentence to french\")\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c29e6b2-462c-4961-bd3b-718bc0e8b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ShellTool\n",
    "\n",
    "shell_tool = ShellTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "593d929d-c579-457e-b2f5-53888a1d5f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import _get_tool_calls_from_response as original_get_tool_calls\n",
    "from uuid import uuid4\n",
    "\n",
    "# Override _get_tool_calls_from_response\n",
    "def _get_tool_calls_from_response(response):\n",
    "    tool_calls = []\n",
    "    if \"message\" in response:\n",
    "        if \"tool_calls\" in response[\"message\"] and response[\"message\"][\"tool_calls\"] is not None:\n",
    "            for tc in response[\"message\"][\"tool_calls\"]:\n",
    "                tool_calls.append(\n",
    "                    tool_call(\n",
    "                        id=str(uuid4()),\n",
    "                        tool_name=tc.get(\"tool_name\"),\n",
    "                        args=tc.get(\"args\"),\n",
    "                    )\n",
    "                )\n",
    "    return tool_calls\n",
    "\n",
    "# Monkey patch\n",
    "import langchain_ollama.chat_models\n",
    "langchain_ollama.chat_models._get_tool_calls_from_response = _get_tool_calls_from_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84683fd1",
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to download the langchain.com webpage and then find all the URLs on it.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"terminal\",\n",
      "  \"action_input\": \"curl -s 'https://langchain.com' > langchain.html; grep -oE 'https?://[^\\\" ]+' langchain.html | sort -u\"\n",
      "}\n",
      "```\n",
      "\u001b[0mExecuting command:\n",
      " curl -s 'https://langchain.com' > langchain.html; grep -oE 'https?://[^\" ]+' langchain.html | sort -u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"terminal\",\n",
      "  \"action_input\": \"curl https://langchain.com/langchain.html && cat langchain.html | grep -oE 'https?://[^\\\" ]+' | sort -u\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " curl https://langchain.com/langchain.html && cat langchain.html | grep -oE 'https?://[^\" ]+' | sort -u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   166  100   166    0     0    792      0 --:--:-- --:--:-- --:--:--   794\n",
      "<html>\n",
      "<head><title>301 Moved Permanently</title></head>\n",
      "<body>\n",
      "<center><h1>301 Moved Permanently</h1></center>\n",
      "<hr><center>openresty</center>\n",
      "</body>\n",
      "</html>\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know that the website returned a 301 error, and I need to figure out how to download the webpage correctly.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"terminal\",\n",
      "  \"action_input\": \"curl -s 'https://langchain.com' > langchain.html; grep -oE 'https?://[^\\\" ]+' langchain.html | sort -u\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " curl -s 'https://langchain.com' > langchain.html; grep -oE 'https?://[^\" ]+' langchain.html | sort -u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I need to download the langchain.com webpage and then find all the URLs on it.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"terminal\",\n",
      "  \"action_input\": \"curl -s 'https://langchain.com' > langchain.html; grep -oE '\\\"https?://[^\\\" ]+\\\"' langchain.html | sort -u\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " curl -s 'https://langchain.com' > langchain.html; grep -oE '\"https?://[^\" ]+\"' langchain.html | sort -u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I need to download the langchain.com webpage and then find all the URLs on it.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"terminal\",\n",
      "  \"action_input\": \"curl -s 'https://langchain.com' > langchain.html; grep -oE '\\\"https?://[^\\\" ]+\\\"' langchain.html | sort -u\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " curl -s 'https://langchain.com' > langchain.html; grep -oE '\"https?://[^\" ]+\"' langchain.html | sort -u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I need to download the langchain.com webpage and then find all the URLs on it.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"terminal\",\n",
      "  \"action_input\": \"curl -s 'https://langchain.com' > langchain.html; grep -oE '\\\"https?://[^\\\" ]+\\\"' langchain.html | sort -u\"\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " curl -s 'https://langchain.com' > langchain.html; grep -oE '\"https?://[^\" ]+\"' langchain.html | sort -u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I need to download the langchain.com webpage and then find all the URLs on it.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"terminal\",\n",
      "  \"action_input\": \"curl -s 'https://langchain.com' > langchain.html; grep -oE '\\\"https?://[^\\\" ]+\\\"' langchain.html | sort -u\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0mExecuting command:\n",
      " curl -s 'https://langchain.com' > langchain.html; grep -oE '\"https?://[^\" ]+\"' langchain.html | sort -u\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_community/tools/shell/tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I need to download the langchain.com webpage and then find all the URLs on it.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"terminal\",\n",
      "  \"action_input\": \"curl -s 'https://langchain.com' > langchain.html; grep -oE '\\\"https?://[^\\\" ]+\\\"' langchain.html | sort -u\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m shell_tool\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;241m=\u001b[39m shell_tool\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshell_tool\u001b[38;5;241m.\u001b[39margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m )\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m self_ask_with_search \u001b[38;5;241m=\u001b[39m initialize_agent(\n\u001b[1;32m     10\u001b[0m     [shell_tool], llm, agent\u001b[38;5;241m=\u001b[39mAgentType\u001b[38;5;241m.\u001b[39mCHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mself_ask_with_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownload the langchain.com webpage and grep for all urls. Return only a sorted list of them. Be sure to use double quotes.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain/chains/base.py:606\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    607\u001b[0m         _output_key\n\u001b[1;32m    608\u001b[0m     ]\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    612\u001b[0m         _output_key\n\u001b[1;32m    613\u001b[0m     ]\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     emit_warning()\n\u001b[0;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain/chains/base.py:389\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    382\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    387\u001b[0m }\n\u001b[0;32m--> 389\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain/chains/base.py:170\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    169\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    171\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain/chains/base.py:160\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    159\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 160\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    165\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    166\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain/agents/agent.py:1629\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1629\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1637\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1638\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1639\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain/agents/agent.py:1337\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1328\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1332\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1333\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m   1335\u001b[0m         [\n\u001b[1;32m   1336\u001b[0m             a\n\u001b[0;32m-> 1337\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1338\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1339\u001b[0m                 color_mapping,\n\u001b[1;32m   1340\u001b[0m                 inputs,\n\u001b[1;32m   1341\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1342\u001b[0m                 run_manager,\n\u001b[1;32m   1343\u001b[0m             )\n\u001b[1;32m   1344\u001b[0m         ]\n\u001b[1;32m   1345\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain/agents/agent.py:1420\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m-> 1420\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain/agents/agent.py:1442\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1450\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_core/tools/base.py:630\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run the tool.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;124;03m    ToolException: If an error occurs during tool execution.\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m CallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m    621\u001b[0m     callbacks,\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m    628\u001b[0m )\n\u001b[0;32m--> 630\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m \u001b[43mcallback_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_tool_start\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Inputs by definition should always be dicts.\u001b[39;49;00m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# For now, it's unclear whether this assumption is ever violated,\u001b[39;49;00m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# but if it is we will send a `None` value to the callback instead\u001b[39;49;00m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO: will need to address issue via a patch.\u001b[39;49;00m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    645\u001b[0m artifact \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages/langchain_core/callbacks/manager.py:1421\u001b[0m, in \u001b[0;36mCallbackManager.on_tool_start\u001b[0;34m(self, serialized, input_str, run_id, parent_run_id, inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run when tool starts running.\u001b[39;00m\n\u001b[1;32m   1403\u001b[0m \n\u001b[1;32m   1404\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;124;03m    CallbackManagerForToolRun: The callback manager for the tool run.\u001b[39;00m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1421\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m \u001b[43muuid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muuid4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1423\u001b[0m handle_event(\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers,\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_tool_start\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1435\u001b[0m )\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CallbackManagerForToolRun(\n\u001b[1;32m   1438\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[1;32m   1439\u001b[0m     handlers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     inheritable_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minheritable_metadata,\n\u001b[1;32m   1446\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/uuid.py:725\u001b[0m, in \u001b[0;36muuid4\u001b[0;34m()\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21muuid4\u001b[39m():\n\u001b[1;32m    724\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate a random UUID.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUUID\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murandom\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/uuid.py:189\u001b[0m, in \u001b[0;36mUUID.__init__\u001b[0;34m(self, hex, bytes, bytes_le, fields, int, version, is_safe)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbytes is not a 16-char string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mbytes\u001b[39m, bytes_), \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mbytes\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mint_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# big endian\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fields \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fields) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m6\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.1:latest\", verbose=True)\n",
    "\n",
    "shell_tool.description = shell_tool.description + f\"args {shell_tool.args}\".replace(\n",
    "    \"{\", \"{{\"\n",
    ").replace(\"}\", \"}}\")\n",
    "self_ask_with_search = initialize_agent(\n",
    "    [shell_tool], llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")\n",
    "self_ask_with_search.run(\n",
    "    \"Download the langchain.com webpage and grep for all urls. Return only a sorted list of them. Be sure to use double quotes.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac295066",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
